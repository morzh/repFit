\subsection{Basic Form}\label{subsec:basic-form}

    Formally consider function, represented by series:
    \begin{equation}\label{eq:equation}
        f(t) \sim a_0 + \sum_{n=1}^{\infty} a_n \sin (n \omega_0 t + \phi_n),
    \end{equation}
    where $a_0$ -- constant, $a_n$ and $\phi_n$, $n \geq 1$ are amplitudes and phase shifts respectively,
    $\omega_0$ is the base frequency, e.g. $\omega_0 = \frac{2\pi}{T}$, $T$  is a period.
    If we make substitution
    \[
        x = \omega_0 t  = \frac{2\pi t}{T},
    \]
    then
    \begin{equation}\label{eq:equation2}
        f(x) \sim a_0 + \sum_{n=1}^{\infty} a_n \sin (n x + \phi_n).
    \end{equation}
    Using trigonometric formula
    \[
        \sin (\alpha +  \beta)  = \sin \alpha \cos \beta + \cos \alpha \sin \beta
    \]
    we get representation
    \begin{equation}\label{eq:equation3}
        f(x) \sim c_{0, 0} + \sum_{n=1}^{\infty} \left( c_{n, 1} \cos nx + c_{n, 2} \sin nx \right).
    \end{equation}
    Note that now amplitude $a_n = \|(c_{n, 1}, c_{n, 2})\|_2$ and phase $\phi_n = \mathrm{atan2} (c_{n, 2}, c_{n, 1})$,
    $a_0 = c_{0, 0}$.

\subsection{Complex Form}\label{subsec:complex-form}

    If we substitute $\cos nx$ and $\sin nx$ with complex exponent
    \begin{align*}
        \cos nx = & \frac{e^{nxi} + e^{-nxi}}{2}   \\
        \sin nx = & \frac{e^{nxi} - e^{-nxi}}{2i} = \frac{e^{-nxi} - e^{nxi}}{2} \\
    \end{align*}
    then we will get the following form of~\ref{eq:equation3}:
    \begin{equation}\label{eq:equation4}
        f(x) \sim \frac{c_{0,0}}{2} + \sum_{n=1}^{\infty} \frac{c_{n, 1} - c_{n, 2}i}{2} e^{nxi} +
        \frac{c_{n, 1} + c_{n, 2}i}{2} e^{-nxi} = \allowbreak  \sum_{k=-\infty}^{+\infty} c_k e^{kxi},
    \end{equation}
    where
    \begin{align}
        c_0 & = \frac{c_{0, 0}}{2} \\
        c_n &= \frac{c_{n,1} - c_{n,2}i}{2} \\
        c_{-n} &= \frac{c_{n,1} + c_{n,2}i}{2},
    \end{align}
    $c_{-n} = c_n^{\ast}$.

\subsection{Fourier Series Convergence Theorems}\label{subsec:fourier-series-convergence}

\subsection{Hilbert Space, briefly}\label{subsec:hilbert-space-briefly}

        Then idea of decomposition some complex object into simpler parts is the best way to tacle the problem.
    On of the approaches is to define some basis (vector of functional) and find object's coordinates in this basis.

    For example if we have orthonormal basis of two vectors $\mathbf{e}_1 = [1, 0]$ and $\mathbf{e}_1 = [0, 1]$
    in a $\mathbb R^2$ plane, then radius vector $\mathbf{v} = [2, 3]$ is decomposed as
    \begin{equation}\label{eq:equation8}
        \mathbf{v} = \mathbf{v}^1 \mathbf{e}_1 + \mathbf{v}^2 \mathbf{e}_2 = 2 \mathbf{e}_1 + 3 \mathbf{e}_2,
    \end{equation}
    where $(2, 3)$ are the coordinates of vector $\mathbf{v}$ in $\{ \mathbf{e}_1, \mathbf{e}_2 \}$ basis.

    But how we get $(2, 3)$ coordinates?
    First option is the make perpendicular projection from the end point of vector $\mathbf{v}$ to lines, produced by bases vectors
    $\mathbf{e}_1$ and $\mathbf{e}_2$.
    Another option is to calculate dot products $\langle \mathbf{v}, \mathbf{e}_1 \rangle = 2$ and
    $\langle \mathbf{v}, \mathbf{e}_2 \rangle = 3$.
    \begin{equation}\label{eq:equation9}
        \mathbf{v} = \langle \mathbf{v}, \mathbf{e}_1 \rangle \  \mathbf{e}_1 +
                     \langle \mathbf{v}, \mathbf{e}_2 \rangle \  \mathbf{e}_2 =
                     2 \mathbf{e}_1 + 3 \mathbf{e}_2.
    \end{equation}

    In the above example, vectors $\mathbf{e}_1$ and $\mathbf{e}_2$ are perpendicular ($\mathbf{e}_1 \perp \mathbf{e}_2$)
    or in other words, $\langle \mathbf{e}_1, \mathbf{e}_2 \rangle = 0$.

    In case when $\mathbf{e}_1 \perp \mathbf{e}_2$ and $\| \mathbf{e}_1 \|_2 \ne 1$ or $\| \mathbf{e}_2 \|_2 \ne 1$,
    things become more interesting.
    Coordinates, obtained from perpendicular projections and dot products are different.
    In case of perpendicular projection, coordinate decreases when respective basis vector length increases (contra-variant coordinate).
    In dot product case coordinate increases, when respective basis vector increases (co-variant coordinate).
    Conversion between two coordinates values could be done with so-called metric tensor.
    The same situation holds when vector basis is not orthogonal (oblique coordinate system).

    In case when we have infinite countable vector basis and each basis vector has infinite elements, it is hard to make perpendicular
    projection from space element to respective basis vector.
    So dot product is the only choice we have.
    \begin{equation}\label{eq:equation5}
        c_i = \sum_{n \in \mathbb N} \mathbf{v}^n_i \mathbf{e}^n_i = \langle \mathbf{v}, \mathbf{e}_i \rangle,
    \end{equation}
    where $c_i$ is the $i-$th component (coordinate) of vector $\mathbf{v}$ in basis
    $\{ \mathbf{e}_1, \mathbf{e}_2, \dots, \mathbf{e}_n, \dots \}$.
    Of course, sum~\eqref{eq:equation5} should converge.

    Let's make one step further.
    We could intuitively consider function as a vector with uncountable number of elements.
    In this continuous case, infinite discrete sum in ~\eqref{eq:equation5} transforms to continuous sum.
    Functional basis remains countable.
    \begin{equation}\label{eq:equation6}
        c_i = \int_{\mathbb R} \mathbf{v}(x) \mathbf{e}_i(x)  dx = \langle \mathbf{v}, \mathbf{e}_i \rangle,
    \end{equation}
    $c_i \in \mathbb R$.
    When $f: \mathbb{C} \to \mathbb{C}$, then
    \begin{equation}\label{eq:equation7}
        c_i = \langle \mathbf{v}, \mathbf{e}_i \rangle = \int_{\mathbb C} \mathbf{v}(x) \mathbf{e}^{\ast}_i(x) dx,
    \end{equation}
    $c_i \in \mathbb C$.

    \subsection{Fourier Transform and It's Inverse}\label{sec:fourier-transform}

        \[
            \mathcal F \{ f(x) \}  = \hat f (\omega) = \langle f(x), e^{i \omega x} \rangle =
            \int_{\mathbb R} f(x) e^{-i \omega x} dx
        \]



Задача 1.
    Прогнать набор видео через сеть:
    https://github.com/isarandi/metrabs

    Как пример можно использовать готовый код из:
    https://colab.research.google.com/github/isarandi/isarandi.github.io/blob/master/eccv22_demo/demo.ipynb

    Тут пара вопросов:
        а. есть ли в сети temporal coherence или она только обрабатывает кадры отдельно;
        б. выдаёт ли сеть достоверности для суставов. Например, если нога в заслоне, то и достоверность соответствующих суставов низкая.

    Как результат выдать видео с нарисованными проекциями 3D суставов на плоскость изображения (видео) и сами анимированные 3х мерные суставы в формате np.ndarray (Nx17x3).
    Замерить скорость работы сети на одну секунду видео (возможно подавать сразу стопку кадров на inference) на данной видеокарте с данным кол-вом глобальной памяти для данных весов (пока можно взять веса по умолчанию).
    Выходной формат: H3.6M, 17 joint (h36m_17). Должно работать следующим образом:
    ```python
    pred = model.detect_poses(img, skeleton='h36m_17')
    ```

Задача 2.
    Дано:
        Видео с тренировкой (возможно на видео есть что-то ещё, не относящееся напрямую к тренировке), скачанное с YouTube, на котором (на самом видео) напечатана некоторая информация.
        Обычно это счётчик секунд, название текущего упражнения (или нескольких), возможно что-то ещё (типа Subscribe and hit bell icon).
    Найти и обработать:
        Общая задача состоит в том, чтобы используя текст из видео создать эпизоды с отдельными упражнениями. В идеале понимать, что эта надпись это название упражнения, а эта надпись -- реклама канала.
        Для начала, научиться определять текст, который находится на видео больше 3-5 секунд. Для этого, можно начать с tesseractOCR (готовое решение -- пакет pytesseract).
        Опять же, для начала брать надписи только на английском. Я бы начал с какого-то одного канала и сделал решение только для него. Потом начал бы обобщать это всё в какую-то систему для всех YouTube каналов.
        Видео придётся скачивать с YouTube тут можно попробовать yt-dlp. Эта задача более творческая, тут надо смотреть, пробовать, думать, проверять
    Выдать:
        JSON или .pickle файл с данными (формат и структура данных пока в свободной форме) для каждого видео. Название файла -- YouTube_video_Id__automatic_chapters.[json | pickle] или как-то ещё.


